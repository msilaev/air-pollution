{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ac0f64",
   "metadata": {},
   "source": [
    "# Forming features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d68be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import sys\n",
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5117eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1991501",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = os.path.join(os.getcwd(), 'data', 'raw')\n",
    "INTERIM_DATA_DIR = os.path.join(os.getcwd(), 'data', 'interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22812fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_pollution_stations=['Helsinki Kallio 2',\n",
    " 'Espoo Leppävaara Läkkisepänkuja',\n",
    " 'Espoo Luukki',\n",
    " 'Helsinki Mannerheimintie',\n",
    " 'Vantaa Tikkurila Neilikkatie',\n",
    " 'Helsinki Vartiokylä Huivipolku',\n",
    " 'Vantaa Kehä III Viinikkala',\n",
    " 'Helsinki Kustaa Vaasan tie']\n",
    "\n",
    "weather_stations= [\n",
    " 'Helsinki Vuosaari satama',\n",
    " 'Helsinki Kaisaniemi',\n",
    " 'Helsinki Kumpula',\n",
    " 'Helsinki Malmi lentokenttä',\n",
    " 'Sipoo Itätoukki']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb93231",
   "metadata": {},
   "source": [
    "forming database for air pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286cdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for station: Helsinki Kallio 2\n",
      "Loaded data for station: Espoo Leppävaara Läkkisepänkuja\n",
      "Loaded data for station: Espoo Luukki\n",
      "Loaded data for station: Helsinki Mannerheimintie\n",
      "Loaded data for station: Vantaa Tikkurila Neilikkatie\n",
      "Loaded data for station: Helsinki Vartiokylä Huivipolku\n",
      "Loaded data for station: Vantaa Kehä III Viinikkala\n",
      "Loaded data for station: Helsinki Kustaa Vaasan tie\n"
     ]
    }
   ],
   "source": [
    "# Loop through all air pollution stations\n",
    "df_air_pollution_total = pd.DataFrame()\n",
    "\n",
    "for station in air_pollution_stations:\n",
    "    # Generate the filename for the station\n",
    "    filename = f\"{station.replace(' ', '_')}_air_pollution_data.parquet\"\n",
    "    full_path = os.path.join(RAW_DATA_DIR, filename)\n",
    "    \n",
    "    # Load the air pollution dataset for the station\n",
    "    if os.path.exists(full_path):\n",
    "        \n",
    "        df_air_pollution = pd.read_csv(full_path)\n",
    "        df_air_pollution['Timestamp'] = pd.to_datetime(df_air_pollution['Timestamp'])\n",
    "        \n",
    "        df_air_pollution.ffill(inplace=True)\n",
    "        df_air_pollution.bfill(inplace=True)\n",
    "\n",
    "        print(f\"Loaded data for station: {station}\")\n",
    "\n",
    "        df_air_pollution = df_air_pollution[[ 'Timestamp', 'Particulate matter < 10 µm', 'Particulate matter < 2.5 µm', 'Nitrogen dioxide'  ]]       \n",
    "                \n",
    "        df_air_pollution = df_air_pollution.rename(columns= {'Particulate matter < 10 µm' : f'Particulate matter < 10 µm_{station}',\n",
    "                                                             'Particulate matter < 2.5 µm' : f'Particulate matter < 2.5 µm_{station}', \n",
    "                                                             'Nitrogen dioxide' : f'Nitrogen dioxide_{station}'})\n",
    "\n",
    "        if df_air_pollution_total.empty:\n",
    "            df_air_pollution_total = df_air_pollution.copy()\n",
    "        else:\n",
    "            df_air_pollution_total = df_air_pollution_total.merge( df_air_pollution, how='outer', on='Timestamp' ) #, suffixes=('', f'_{station}'))        \n",
    "\n",
    "    else:\n",
    "        print(f\"File not found for station: {station}\")\n",
    "        continue\n",
    "\n",
    "df_air_pollution_total.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db7ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_total = pd.DataFrame()\n",
    "\n",
    "for station in weather_stations:\n",
    "    # Generate the filename for the station\n",
    "    filename = f\"{station.replace(' ', '_')}_weather_data.csv\"\n",
    "    full_path = os.path.join(RAW_DATA_DIR, filename)\n",
    "\n",
    "    # Load the weather dataset for the station\n",
    "    if os.path.exists(full_path):\n",
    "        df_weather = pd.read_csv(full_path)\n",
    "        df_weather['Timestamp'] = pd.to_datetime(df_weather['Timestamp'])\n",
    "        #print(f\"Null value counts for station {station} before filling:\")\n",
    "        #print(df_weather.isnull().sum())\n",
    "        df_weather.ffill( inplace=True)\n",
    "        df_weather.bfill( inplace=True)\n",
    "        #print(f\"Loaded data for station: {station}\")\n",
    "\n",
    "        # Select relevant columns\n",
    "        df_weather = df_weather[['Timestamp', \"Air temperature\", \"Wind speed\", \"Gust speed\"]]\n",
    "\n",
    "        # Rename columns to include the station name (if you intend to track by station)\n",
    "        df_weather = df_weather.rename(columns={\n",
    "            \"Air temperature\": f\"Air temperature_{station}\",\n",
    "            \"Wind speed\": f\"Wind speed_{station}\",\n",
    "            \"Gust speed\": f\"Gust speed_{station}\"\n",
    "        })\n",
    "\n",
    "        if df_weather_total.empty:\n",
    "            df_weather_total = df_weather.copy()\n",
    "        else:\n",
    "            df_weather_total = pd.merge(df_weather_total, df_weather, how='outer', on='Timestamp')\n",
    "\n",
    "    else:\n",
    "        print(f\"File not found for station: {station}\")\n",
    "        continue\n",
    "\n",
    "df_weather_total.ffill(inplace=True)\n",
    "df_weather_total.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f231dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_total.to_csv(os.path.join(INTERIM_DATA_DIR, 'weather_data_total.csv'), index=False)\n",
    "df_air_pollution_total.to_csv(os.path.join(INTERIM_DATA_DIR, 'air_pollution_data_total.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
